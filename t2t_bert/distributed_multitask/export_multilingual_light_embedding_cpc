config_file=./BERT/data/textcnn/textcnn_multilingual_embedding_light_dgcnn_v1_bi.json
init_checkpoint=sentence_pair/pretrain_gatedcnn_lm/cpc_cls/vae_bow/pretrained_light_dgcnn/normal/disc_bi_ligthconv_v1_circle_loss/model.ckpt-1546842
vocab_file=sentence_pair/vocab_mbert.txt
label_id=./BERT/data/lazada_multilingual/label_dict.json
max_length=128
train_file=lazada/new_data/20190415/data/train_tfrecords
dev_file=lazada/new_data/20190415/data/dev_tfrecords
model_output=sentence_pair/pretrain_gatedcnn_lm/cpc_cls/vae_bow/pretrained_light_dgcnn/normal/disc_bi_ligthconv_v1_circle_loss/
export_dir=sentence_pair/pretrain_gatedcnn_lm/cpc_cls/vae_bow/pretrained_light_dgcnn/normal/disc_bi_ligthconv_v1_circle_loss/export/1546842/1024
epoch=100
num_classes=4
train_size=1000000
eval_size=190190
batch_size=128
model_type=textcnn
label_type=multi_label
if_shard=2
is_debug=1
run_type=estimator
opt_type="all_reduce"
num_gpus=1
parse_type=parse_batch
rule_model=normal
profiler="no"
train_op=adam
running_type=train
cross_tower_ops_type=paisoar
distribution_strategy=MirroredStrategy
load_pretrained=yes
warmup=no
decay=no
with_target=""
input_target="a"
distillation="normal"
temperature=2.0
distillation_ratio=1.0
num_hidden_layers=12
task_type=single_sentence_classification
classifier=order_classifier
mode="multi_task"
multi_task_type="lcqmc,paws,cmnli,afqmc,wsdm,ccks"
multi_task_config="./BERT/t2t_bert/distributed_multitask/textcnn_multilingual_embedding_dgcnn.json"
task_invariant=no
init_lr=1e-3
multitask_balance_type=data_balanced
pretrained_w2v_path=sentence_pair/vocab_w2v.txt