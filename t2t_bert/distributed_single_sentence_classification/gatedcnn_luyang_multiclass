config_file=./BERT/data/textcnn/textcnn_chinese_emebdding_light_dgcnn_v1_bi_tiny.json
init_checkpoint=bert_pretrain/open_domain/pretrained_model/gatedcnn/light_conv_chinese_tiny_disc_bi/model.ckpt-976550
vocab_file=chinese_L-12_H-768_A-12/vocab.txt
label_id=./BERT/data/green/label_dict.json
max_length=384
train_file=luyang/all_0921_train.tfrecord
dev_file=luyang/all_0921_dev.tfrecord
model_output=luyang/all_0921_dgcnn_tiny_v1/
epoch=20
label_type='multi_label'
loss='circle_loss'
num_classes=8
train_size=218694
eval_size=54673
batch_size=64
model_type=textcnn
if_shard=2
is_debug=1
run_type=estimator
opt_type="all_reduce"
num_gpus=1
parse_type=parse_batch
rule_model=normal
profiler="no"
train_op=adam_weight_decay_exclude
running_type=train
cross_tower_ops_type=paisoar
distribution_strategy=MirroredStrategy
load_pretrained=yes
apply_cpc=none
warmup=none
decay=none
with_target=""
input_target=""
distillation="normal"
temperature=2.0
distillation_ratio=1.0
num_hidden_layers=12
task_type=single_sentence_multilabel_classification_bert
classifier=order_classifier
mode="single_task"
init_lr=1e-4