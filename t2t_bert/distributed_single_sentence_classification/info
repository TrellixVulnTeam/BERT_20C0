我想了想 预训练落地的方法，即使 给出这些结论 也不一定 能推广：
1. 预训练的意义在于 提供更好的初始化：
   1. 使用开源的、自己 从头开始训练的不重要
   2. 开源 的模型 不一定能给出 所需的尺寸---》必然需要 自己 具备 pretrain的能力
   3. 当有了 类似尺寸的模型，在 开源的基础、自己从头开始训练的基础上做 都可以：
      1. 除非有特别 novel的改进，经验性的改进 之前的文章 都有 相关的结果，总结并选择 相关的配置即可（google、facebook等已经 做了大量的实验，没必要 再重复一次）
2. 在团队推广使用：
   1. 类似 pai-easytrasnfer、九鼎等，同样的东西 做两套，分布式也是（pai-soar、auto-parallel），团队之间 刷业务 等 必然 会 考虑 自己做 一个新的（除非 数据壁垒、算力壁垒、方向壁垒）
   2. 推广的方式：上下游
      1. 我们给出 各个场景、任务、尺寸的 模型，由 业务同学 自己选择
      2. 业务 同学 自己构建 benchmark，选择相关的模型 并给出 评价指标和结果：
         1. 不能满足需求的时候，自然会考虑 使用 业务数据相关的模型
         2. 性能不满足要求的时候 必然考虑 使用 合适尺寸 的模型 从头开始训练
      3. 吐槽：
         1. 比如 hanfei 的 去重模块：
            1. 没有 公开数据集的测试（测试embedding的universal 能力）
            2. 没有 明确的 评价指标
            3. 只预训练了一次，后面 基本 也很少改动
         2. luyang 自己拿 electra-small 训练 交互场景的模型：
            1. 没有 明确指标
            2. 没有 和 其他模型 的对比结果
3. 团队 统一 模型重要，反馈 更重要：
    1. 为了业绩 等，大家 倾向于 自己 弄，很少给反馈
    2. 即使有反馈，很多也是 使用不当的问题：
       比如 embedding特征，在 两个句子重合度95%以上的时候，embedding就是区分不了，开始的时候 就不该 这么用，用了给 负反馈 意义不大
    3. 之前 只有 卫苏 有 反馈，放到群里面的 模型（包括 公开评测的结果 等）基本 没有人过问，使用 之类的
4. 